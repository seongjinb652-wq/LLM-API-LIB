# ============================================
# ğŸ“Œ response_parser.py
# ëª©ì : LLM API í˜¸ì¶œ ê²°ê³¼ì—ì„œ ì‘ë‹µ ì •ë³´ ì¶œë ¥ ë° ë‹µë³€ íŒŒì‹± í•¨ìˆ˜ ì •ì˜
# - ì‚¬ìš©ëœ ëª¨ë¸ëª…, ë‹µë³€ ë‚´ìš©, ì…ë ¥/ì¶œë ¥ í† í° ìˆ˜ ì¶œë ¥
# - parse_answer í•¨ìˆ˜: ì‘ë‹µ ê°ì²´ì—ì„œ GPT ë‹µë³€ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
# - êµìœ¡/ë°ëª¨ìš© ì˜ˆì‹œ ì½”ë“œë¡œ, ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì‘ë‹µ ë¡œê¹…/ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆë¡œ í™•ì¥ ê°€ëŠ¥
# ============================================

print(f"ì‚¬ìš©ëœ ëª¨ë¸ : {response.model}")
print(f"ë‹µë³€ : {response.choices[0].message.content}")
print(f"ì…ë ¥ í† í° ìˆ˜ : {response.usage.prompt_tokens}")
print(f"ì¶œë ¥ í† í° ìˆ˜ : {response.usage.completion_tokens}")
# API í˜¸ì¶œ ê²°ê³¼ ì¤‘ GPTì˜ ë‹µë³€ì„ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
def parse_answer(response):
    return response.choices[0].message.content
